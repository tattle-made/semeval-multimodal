{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.130 (installed: 0.4.128).\n",
      "NVMLError: NVML Shared Library Not Found - GPU usage metrics may not be reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/kruttikanadig/sandbox/e/SAN-38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(SAN-38)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Neptune experiment\n",
    "# Comment out lines beginning with neptune. in this notebook if not using Neptune for ML experiment logging\n",
    "\n",
    "neptune.init(project_qualified_name=os.environ[\"NEPTUNE_PROJECT\"], api_token=os.environ[\"NEPTUNE_API_TOKEN\"])\n",
    "\n",
    "neptune.create_experiment(name=\"22012021_01\", \n",
    "                          params=training_params,\n",
    "                          tags=[\"multimodal\", \"80-20\", \"607-samples\"],\n",
    "                          upload_source_files=[\"SemEval-subtask3.ipynb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch import cuda\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, FeatureExtractionPipeline, pipeline, RobertaTokenizer, RobertaModel, XLNetModel, XLNetTokenizer\n",
    "from pprint import pprint\n",
    "import random\n",
    "import neptune\n",
    "import itertools\n",
    "import subprocess\n",
    "import logging\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from PIL import Image\n",
    "import sentencepiece as spm\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/training_set_task3/training_set_task3.txt\"\n",
    "dev_path = \"data/dev_set_task3/dev_set_task3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to read data and convert each item's text labels into binary labels\n",
    "def read_data(path, inference=False):\n",
    "\n",
    "    with open (path, \"r\") as f:\n",
    "        data_raw = f.read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        df = pd.DataFrame(data_json)\n",
    "        \n",
    "    if inference == False:\n",
    "        all_labels = list(df[\"labels\"].explode().unique())\n",
    "        all_labels.pop(1)\n",
    "        \n",
    "        def encode_labels(labels):\n",
    "            encoded = [1 if l in labels else 0 for l in all_labels]\n",
    "            return encoded\n",
    "        \n",
    "        df[\"label_list\"] = df[\"labels\"].map(encode_labels)\n",
    "        return df,  all_labels\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>image</th>\n",
       "      <th>label_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>[Black-and-white Fallacy/Dictatorship, Name ca...</td>\n",
       "      <td>THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n</td>\n",
       "      <td>128_image.png</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>[Transfer, Reductio ad hitlerum, Smears]</td>\n",
       "      <td>This is not an accident!</td>\n",
       "      <td>189_image.png</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>[Loaded Language, Name calling/Labeling, Smear...</td>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>96_image.png</td>\n",
       "      <td>[0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             labels  \\\n",
       "0  128  [Black-and-white Fallacy/Dictatorship, Name ca...   \n",
       "1  189           [Transfer, Reductio ad hitlerum, Smears]   \n",
       "2   96  [Loaded Language, Name calling/Labeling, Smear...   \n",
       "\n",
       "                                                text          image  \\\n",
       "0    THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n  128_image.png   \n",
       "1                           This is not an accident!  189_image.png   \n",
       "2  SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   96_image.png   \n",
       "\n",
       "                                          label_list  \n",
       "0  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, all_labels = read_data(train_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters and info that will be logged in Neptune\n",
    "training_params = {\"model\": \"Fusion\",\n",
    "                   \"epochs\": 1,\n",
    "                   \"optimizer\": \"Adam\",\n",
    "                   \"learning_rate\": 0.0001,\n",
    "                   \"train_batch_size\": 8,\n",
    "                   \"val_batch_size\": 8,\n",
    "                   \"max_len\": 200,\n",
    "                   \"shuffle\":False,\n",
    "                   \"num_workers\": 0,\n",
    "                   \"loss_fn\": \"BCEWithLogitsLoss\",\n",
    "                   \"metric1\": \"train_f1_micro\",\n",
    "                   \"metric2\": \"train_f1_macro\",\n",
    "                   \"metric3\": \"val_f1_micro\",\n",
    "                   \"metric4\": \"val_f1_macro\",\n",
    "                   \"dropout\": 0.2,\n",
    "                   \"language_model\": \"bert\",\n",
    "                   \"vision_model\": \"resnet18\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class for loading the training data\n",
    "\n",
    "# Image transformation function\n",
    "transformations=transforms.Compose([\n",
    "                    transforms.Resize((224,224)), \n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, transform, df, tokenizer, max_len):\n",
    "        self.img_dir=img_dir\n",
    "        self.transform=transform\n",
    "        self.img_names=df[\"image\"].values\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.text = df[\"text\"].values\n",
    "        self.targets = df[\"label_list\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        # The inputs below are required by BERT. See Huggingface's BERT documentation\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        # For each img_name in img_names, load the corresponding img from the img folder\n",
    "        img = Image.open(os.path.join(self.img_dir, self.img_names[index])).convert('RGB')\n",
    "        # Return the transformed RGB image\n",
    "        if self.transform is not None:\n",
    "            img_vector=self.transform(img)\n",
    "        \n",
    "        # For each item in the dataset, returns the item's text and image information together in the form of ids, mask, token_type_ids, img_vector\n",
    "        # Also return the item's true labels (targets)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'img_vector': img_vector\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader\n",
    "\n",
    "dataset = CustomDataset(img_dir=\"data/training_set_task3\",\n",
    "                        transform=transformations,\n",
    "                        df=df, \n",
    "                        tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'), \n",
    "                        max_len=training_params[\"max_len\"])\n",
    "\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=training_params[\"train_batch_size\"],\n",
    "                        num_workers=training_params[\"num_workers\"],\n",
    "                        worker_init_fn=random.seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multimodal model fusing BERT and ResNet\n",
    "\n",
    "class FusionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # BERT layers - language model\n",
    "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True, return_dict=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.bert_features = nn.Sequential(nn.Linear(768, 256), # Transform 768 dim Bert vectors into 256\n",
    "                                nn.LogSoftmax(dim=1))\n",
    "        # Resnet layers - vision model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Replace the default ResNet classifier layer \n",
    "        classifier_input = self.resnet.fc.in_features\n",
    "        classifier = nn.Sequential(nn.Linear(classifier_input, 256), # Transform 512 dim Resnet vectors into 256\n",
    "                             nn.LogSoftmax(dim=1)) \n",
    "        self.resnet.fc = classifier\n",
    "        self.fusion_classifier = nn.Linear(512, 22) # 22 labels\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids, img_vector): # dataloader items\n",
    "        # Apply language model\n",
    "        bert_outputs = self.bert(ids, mask, token_type_ids)\n",
    "        bert_outputs = self.bert_features(self.dropout(bert_outputs[1]))\n",
    "        # Apply vision model\n",
    "        resnet_outputs = self.resnet(img_vector)\n",
    "#         print(resnet_outputs.size())\n",
    "        # Concatenate\n",
    "        fused = torch.cat([bert_outputs, resnet_outputs], dim=1)\n",
    "        return self.fusion_classifier(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FusionModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (bert_features): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LogSoftmax()\n",
       "    )\n",
       "  )\n",
       "  (fusion_classifier): Linear(in_features=512, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FusionModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and randomly split dataset into 80:20 training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training function\n",
    "\n",
    "def train(epochs):\n",
    "    \n",
    "    def loss_fn(outputs, targets):\n",
    "        return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "    \n",
    "    def calculate_metrics(outputs, targets):\n",
    "        f1_micro = metrics.f1_score(targets, outputs, average=\"micro\")\n",
    "        f1_macro = metrics.f1_score(targets, outputs, average=\"macro\")\n",
    "        return f1_micro, f1_macro\n",
    "    \n",
    "    def make_preds(outputs, targets, fin_outputs, fin_targets):\n",
    "        outputs = (np.array(torch.sigmoid(outputs).cpu().detach().numpy().tolist()) >= 0.5).astype(int).tolist()\n",
    "        targets = np.array(targets.cpu().detach().numpy().tolist()).astype(int).tolist()\n",
    "        fin_targets.extend(targets)\n",
    "        fin_outputs.extend(outputs)\n",
    "        return fin_outputs, fin_targets\n",
    "    \n",
    "    def validate(model, validation_loader):\n",
    "        val_targets=[]\n",
    "        val_outputs=[]\n",
    "        model.eval()\n",
    "        \n",
    "        for _,data in enumerate(validation_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            img_vector = data[\"img_vector\"].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids, img_vector)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            print(\"Validation Loss: {}\".format(loss.item()))\n",
    "            neptune.log_metric(\"Validation epoch\", epoch+1)\n",
    "            neptune.log_metric(\"Validation batch\", _)\n",
    "            neptune.log_metric(\"Validation loss\", loss.item())\n",
    "            \n",
    "            val_outputs, val_targets = make_preds(outputs, targets, val_outputs, val_targets)\n",
    "        \n",
    "        return val_outputs, val_targets\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "            \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=training_params[\"learning_rate\"])\n",
    "    model.train()\n",
    "    train_targets=[]\n",
    "    train_outputs=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}\".format(epoch+1))\n",
    "        \n",
    "        for _,data in enumerate(training_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            img_vector = data[\"img_vector\"].to(device, dtype = torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids, img_vector)\n",
    "            \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            print(\"Train Loss: {}\".format(loss.item()))\n",
    "            neptune.log_metric(\"Train epoch\", epoch+1)\n",
    "            neptune.log_metric(\"Train batch\", _)\n",
    "            neptune.log_metric(\"Train loss\", loss.item())\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch == (epochs-1):\n",
    "                train_outputs, train_targets = make_preds(outputs, targets, train_outputs, train_targets)\n",
    "                \n",
    "        val_outputs, val_targets = validate(model, validation_loader)\n",
    "    \n",
    "    \n",
    "    train_f1_micro, train_f1_macro = calculate_metrics(train_outputs, train_targets)\n",
    "    print(\"Train F1 Micro score: \", train_f1_micro)\n",
    "    print(\"Train F1 Macro score: \", train_f1_macro)\n",
    "    neptune.log_metric(\"Train f1_micro\", train_f1_micro)\n",
    "    neptune.log_metric(\"Train f1_macro\", train_f1_macro)\n",
    "    \n",
    "    val_f1_micro, val_f1_macro = calculate_metrics(val_outputs, val_targets)\n",
    "    print(\"Validation F1 Micro score: \", val_f1_micro)\n",
    "    print(\"Validation F1 Macro score: \", val_f1_macro)\n",
    "    neptune.log_metric(\"Validation f1_micro\", val_f1_micro)\n",
    "    neptune.log_metric(\"Validation f1_macro\", val_f1_macro)\n",
    "    \n",
    "    # The next chunk of code is for prediction analysis and debugging\n",
    "    \n",
    "    t_outputs = [0]*22\n",
    "    t_targets = [0]*22\n",
    "    for i in range(0, len(train_outputs)):\n",
    "        t_outputs = list(map(np.add, t_outputs, train_outputs[i]))\n",
    "        t_targets = list(map(np.add, t_targets, train_targets[i]))\n",
    "        \n",
    "    v_outputs = [0]*22\n",
    "    v_targets = [0]*22\n",
    "    for i in range(0, len(val_outputs)):\n",
    "        v_outputs = list(map(np.add, v_outputs, val_outputs[i]))\n",
    "        v_targets = list(map(np.add, v_targets, val_targets[i]))\n",
    "    \n",
    "    print(\"True train labels\")\n",
    "    print(t_targets)\n",
    "    print(\"Train predictions per label\")\n",
    "    print(t_outputs)\n",
    "    print(\"True validation labels\")\n",
    "    print(v_targets)\n",
    "    print(\"Validation predictions per label\")\n",
    "    print(v_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.25940197706222534\n",
      "Train Loss: 0.35454556345939636\n",
      "Train Loss: 0.21527276933193207\n",
      "Train Loss: 0.28943657875061035\n",
      "Train Loss: 0.3271448016166687\n",
      "Train Loss: 0.23761028051376343\n",
      "Train Loss: 0.3069416284561157\n",
      "Train Loss: 0.31029272079467773\n",
      "Train Loss: 0.2723110318183899\n",
      "Train Loss: 0.3150988221168518\n",
      "Train Loss: 0.23621167242527008\n",
      "Train Loss: 0.16730831563472748\n",
      "Train Loss: 0.29132020473480225\n",
      "Train Loss: 0.2430778443813324\n",
      "Train Loss: 0.323095440864563\n",
      "Train Loss: 0.2036229521036148\n",
      "Train Loss: 0.20329636335372925\n",
      "Train Loss: 0.24246688187122345\n",
      "Train Loss: 0.2264920175075531\n",
      "Train Loss: 0.41025158762931824\n",
      "Train Loss: 0.294776052236557\n",
      "Train Loss: 0.2263338565826416\n",
      "Train Loss: 0.37485063076019287\n",
      "Train Loss: 0.21027569472789764\n",
      "Train Loss: 0.25249454379081726\n",
      "Train Loss: 0.26419007778167725\n",
      "Train Loss: 0.1692648082971573\n",
      "Train Loss: 0.22729559242725372\n",
      "Train Loss: 0.20760971307754517\n",
      "Train Loss: 0.2601621150970459\n",
      "Train Loss: 0.26518046855926514\n",
      "Train Loss: 0.2616758644580841\n",
      "Train Loss: 0.30216559767723083\n",
      "Train Loss: 0.21840928494930267\n",
      "Train Loss: 0.22168035805225372\n",
      "Train Loss: 0.18194517493247986\n",
      "Train Loss: 0.2097540944814682\n",
      "Train Loss: 0.18856358528137207\n",
      "Train Loss: 0.2096375823020935\n",
      "Train Loss: 0.2976074516773224\n",
      "Train Loss: 0.32851311564445496\n",
      "Train Loss: 0.24036364257335663\n",
      "Train Loss: 0.19445867836475372\n",
      "Train Loss: 0.2065628170967102\n",
      "Train Loss: 0.26392489671707153\n",
      "Train Loss: 0.21605859696865082\n",
      "Train Loss: 0.3041095733642578\n",
      "Train Loss: 0.34470275044441223\n",
      "Train Loss: 0.23221983015537262\n",
      "Train Loss: 0.29681992530822754\n",
      "Train Loss: 0.22724409401416779\n",
      "Train Loss: 0.22178445756435394\n",
      "Train Loss: 0.2545427680015564\n",
      "Train Loss: 0.23176966607570648\n",
      "Train Loss: 0.2450840026140213\n",
      "Train Loss: 0.28155261278152466\n",
      "Train Loss: 0.2294534295797348\n",
      "Train Loss: 0.2051379233598709\n",
      "Train Loss: 0.27737948298454285\n",
      "Train Loss: 0.3014393150806427\n",
      "Train Loss: 0.23376180231571198\n",
      "Validation Loss: 0.16481663286685944\n",
      "Validation Loss: 0.30790087580680847\n",
      "Validation Loss: 0.295108437538147\n",
      "Validation Loss: 0.21547187864780426\n",
      "Validation Loss: 0.2167586237192154\n",
      "Validation Loss: 0.20910176634788513\n",
      "Validation Loss: 0.16495844721794128\n",
      "Validation Loss: 0.3663848638534546\n",
      "Validation Loss: 0.17204445600509644\n",
      "Validation Loss: 0.25555169582366943\n",
      "Validation Loss: 0.28354883193969727\n",
      "Validation Loss: 0.3301577866077423\n",
      "Validation Loss: 0.18640083074569702\n",
      "Validation Loss: 0.20688050985336304\n",
      "Validation Loss: 0.19537073373794556\n",
      "Validation Loss: 0.17484904825687408\n",
      "Train F1 Micro score:  0.4888658726048679\n",
      "Train F1 Macro score:  0.06173668229004197\n",
      "Validation F1 Micro score:  0.5284552845528455\n",
      "Validation F1 Macro score:  0.0630654624563254\n",
      "True train labels\n",
      "[15, 312, 48, 13, 259, 50, 39, 71, 21, 27, 32, 50, 7, 56, 52, 4, 43, 16, 2, 15, 2, 0]\n",
      "Train predictions per label\n",
      "[0, 458, 0, 0, 339, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True validation labels\n",
      "[4, 81, 13, 2, 56, 16, 6, 13, 10, 5, 4, 10, 3, 12, 9, 1, 4, 4, 0, 4, 0, 0]\n",
      "Validation predictions per label\n",
      "[0, 116, 0, 0, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = train(epochs=training_params[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models can be large - comment this out if not required\n",
    "def save_model(PATH):\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "save_model(PATH=\"state_dict_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SemEval - modify as required\n",
    "def generate_prediction_file(df, preds):\n",
    "    \n",
    "    # Define function to get original text labels from predicted binary labels\n",
    "    def get_labels(pred_list):\n",
    "        labels = [all_labels[idx] for idx, pred in enumerate(pred_list) if pred == 1]\n",
    "        return labels\n",
    "    \n",
    "    df[\"preds\"] = preds\n",
    "    df[\"pred_labels\"] = df[\"preds\"].map(get_labels)\n",
    "    preds_df = df[[\"id\", \"pred_labels\"]].copy()\n",
    "    preds_df.rename(columns={\"pred_labels\":\"labels\"}, inplace=True)\n",
    "    preds_json = preds_df.to_json(orient=\"records\")\n",
    "    with open('preds.txt', 'w') as f:\n",
    "        f.write(preds_json)\n",
    "    print(\"Predictions file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_file(train_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.log_artifact(\"preds.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune.log_artifact(\"state_dict_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "PATH=\"state_dict_model.pt\"\n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class for loading test data\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, transform, df, tokenizer, max_len):\n",
    "        self.img_dir=img_dir\n",
    "        self.transform=transform\n",
    "        self.img_names=df[\"image\"].values\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.text = df[\"text\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        # For each img_name in img_names, load the corresponding img from the img folder\n",
    "        img = Image.open(os.path.join(self.img_dir, self.img_names[index])).convert('RGB')\n",
    "        # Return the transformed RGB image\n",
    "        if self.transform is not None:\n",
    "            img_vector=self.transform(img)\n",
    "            \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'img_vector': img_vector\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dev set\n",
    "dev_df = read_data(dev_path, inference=True)\n",
    "\n",
    "dev_set = TestDataset(img_dir=\"data/dev_set_task3\",\n",
    "                        transform=transformations,\n",
    "                        df=dev_df, \n",
    "                        tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'), \n",
    "                        max_len=training_params[\"max_len\"])\n",
    "\n",
    "dev_loader = DataLoader(dev_set, \n",
    "                             batch_size=training_params[\"train_batch_size\"],\n",
    "                             num_workers=training_params[\"num_workers\"],\n",
    "                             worker_init_fn=random.seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testing_loader, model):\n",
    "    model.eval()\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            img_vector = data[\"img_vector\"].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids, img_vector)\n",
    "            outputs = (np.array(torch.sigmoid(outputs).cpu().detach().numpy().tolist()) >= 0.5).astype(int).tolist()\n",
    "            fin_outputs.extend(outputs)\n",
    "    return fin_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_preds = test(dev_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_file(dev_df, dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.log_artifact(\"preds.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "neptune": {
   "notebookId": "32783039-95ac-4a3c-bffe-bffb0cca96a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
